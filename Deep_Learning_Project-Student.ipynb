{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64ff744-6734-4e08-8e46-4fe2407bb251",
   "metadata": {},
   "source": [
    "# Final Project - Fundamentals of Deep Learning for NLP and CV\n",
    "\n",
    "Congratulations! This is the final project!\n",
    "\n",
    "\n",
    "## Delivery of Project\n",
    "\n",
    "This jupyter notebook is to be delivered to evaluate your knowledge on the Deep Learning for NLP and CV module at Rumos, before date agreed with the professor. Please add your name and e-mail next.\n",
    "\n",
    "**Student Name**: \"Nuno Pereira\"  \n",
    "**E-mail**: \"pereiranuno88@gmail.com\"\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Details on the dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Plagiarism\n",
    "\n",
    "Always remember that you are here to learn. Discussions on the final project are highly incentivised but please do not share your work. The struggle to solve the problems is needed in order to become a true Data Scientist. By allowing others to use your code you are making the world a worse place: you are not truly helping your colleague, and you are not promoting discussions on the topic.\n",
    "\n",
    "In case you need help, or just want to discuss some project-related topics, reach out to me either through email or through a Slack direct message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fa7de-7c3d-4e0b-82bd-18ac23860c14",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "Please solve the following exercises by creating a markdown cell with **# EXERCISE >>NUMBER<<**  just before you solve it (you can use the number of cells you need after that).\n",
    "\n",
    "## Evaluation\n",
    "Points (of a total of 100%):\n",
    "1. 20%  \n",
    "2. 20%  \n",
    "3. 20%  \n",
    "4. 20%  \n",
    "5. 20%  \n",
    "\n",
    "Final 5% for additional effort and conclusions beyond what was asked (give your _extra mile_).\n",
    "\n",
    "## Important notes\n",
    "1. Data Science is all about *flow*. Keep your analysis work-flow consistent.  \n",
    "2. When it is requested you to *describe* something, please be 1. skeptic, 2. objective, and 3. succinct! \n",
    "3. If you don't know: search, invent, study, but please don't leave any exercise blank.\n",
    "\n",
    "### Good luck!\n",
    "# 3, 2, 1, GO! GO! GO!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e17bd-3d86-4019-b609-4e93b0884253",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc0c7d4-bfb4-4c64-82c3-aef54bda1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea91d024-dd84-4c29-a975-d0791c3f2111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1dd0576d030>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global variables for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb49e89-3f99-4fdb-ad90-82383b506124",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc101e60-60d5-4765-b511-a21c6c816637",
   "metadata": {},
   "source": [
    "### CIFAR-10Dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. \n",
    "\n",
    "<img src=\"images/cifar10.png\" width=\"400\" height=\"100\">\n",
    "\n",
    "[CIFAR 10](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e25ea8-b589-45f3-80d8-78477a49d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57edfa7c-ac43-4e7e-adfc-1d9728807a3a",
   "metadata": {},
   "source": [
    "### Twitter Dataset\n",
    "\n",
    "[Source - huggingface.co/datasets - carblacac/twitter-sentiment-analysis](https://huggingface.co/datasets/carblacac/twitter-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ddbad3-7822-4ff9-b6d8-cb2e85214f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv(\"data/twitter.csv\", sep=\"\\t\", header=None, names=[\"target\", \"text\"])\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a58143-f218-4674-bca5-3f79d9115e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc16e8-b519-4e20-8d9d-0d0a81d58474",
   "metadata": {},
   "source": [
    "# EXERCISE 1 - Use CIFAR10 Dataset\n",
    "\n",
    "```classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')```\n",
    "\n",
    "- Build a simple Neural Network without using convolutional layers to predict the image class\n",
    "    - No need to configure the optimization, loss function or predict yet. Only implement the NN architecture as ```class NeuralNetwork(nn.Module)```\n",
    "- Explain your choices for the model architecture e.g., activation layer, input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d42299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a45d8d8-c9bf-49c1-a819-56265ac8842c",
   "metadata": {},
   "source": [
    "# Exercise 2 - Use CIFAR10 Dataset\n",
    "- Set the optimizer, loss function and train your model\n",
    "    - Explain your choices for the optimizer and loss function\n",
    "- Check the performance of your model\n",
    "    - Chose the metric and explain your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e4040-d39a-44e4-a93d-0d6d680aed54",
   "metadata": {},
   "source": [
    "# Exercise 3 - Use CIFAR10 Dataset\n",
    "- Same as Exercise 1 but now add Convolutional Layers\n",
    "- Explain your choices for the model architecture e.g., activation layer, input and output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f908f6-9c28-4c07-bb2c-c0bd54326f92",
   "metadata": {},
   "source": [
    "# Exercise 4 - Use CIFAR10 Dataset\n",
    "- Same as Exercise 2 but for the CNN arquitecture (model from Exercise 3)\n",
    "\n",
    "- Set the optimizer, loss function and train your model\n",
    "    - Explain your choices for the optimizer and loss function\n",
    "- Check the performance of your model\n",
    "    - Chose the metric and explain your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c8d7a-1808-4715-8fe5-8c1bb5a1e00f",
   "metadata": {},
   "source": [
    "# Exercise 5 - Use Twitter Dataset\n",
    "For the **Text DATA TODO**\n",
    "\n",
    "- Build a Supervised Classification model\n",
    "- Explain your choices for preparing the text for the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
