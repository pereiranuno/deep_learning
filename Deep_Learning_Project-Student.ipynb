{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64ff744-6734-4e08-8e46-4fe2407bb251",
   "metadata": {},
   "source": [
    "# Final Project - Fundamentals of Deep Learning for NLP and CV\n",
    "\n",
    "Congratulations! This is the final project!\n",
    "\n",
    "\n",
    "## Delivery of Project\n",
    "\n",
    "This jupyter notebook is to be delivered to evaluate your knowledge on the Deep Learning for NLP and CV module at Rumos, before date agreed with the professor. Please add your name and e-mail next.\n",
    "\n",
    "**Student Name**: \"Nuno Pereira\"  \n",
    "**E-mail**: \"pereiranuno88@gmail.com\"\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Details on the dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Plagiarism\n",
    "\n",
    "Always remember that you are here to learn. Discussions on the final project are highly incentivised but please do not share your work. The struggle to solve the problems is needed in order to become a true Data Scientist. By allowing others to use your code you are making the world a worse place: you are not truly helping your colleague, and you are not promoting discussions on the topic.\n",
    "\n",
    "In case you need help, or just want to discuss some project-related topics, reach out to me either through email or through a Slack direct message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fa7de-7c3d-4e0b-82bd-18ac23860c14",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "Please solve the following exercises by creating a markdown cell with **# EXERCISE >>NUMBER<<**  just before you solve it (you can use the number of cells you need after that).\n",
    "\n",
    "## Evaluation\n",
    "Points (of a total of 100%):\n",
    "1. 20%  \n",
    "2. 20%  \n",
    "3. 20%  \n",
    "4. 20%  \n",
    "5. 20%  \n",
    "\n",
    "Final 5% for additional effort and conclusions beyond what was asked (give your _extra mile_).\n",
    "\n",
    "## Important notes\n",
    "1. Data Science is all about *flow*. Keep your analysis work-flow consistent.  \n",
    "2. When it is requested you to *describe* something, please be 1. skeptic, 2. objective, and 3. succinct! \n",
    "3. If you don't know: search, invent, study, but please don't leave any exercise blank.\n",
    "\n",
    "### Good luck!\n",
    "# 3, 2, 1, GO! GO! GO!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e17bd-3d86-4019-b609-4e93b0884253",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc0c7d4-bfb4-4c64-82c3-aef54bda1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea91d024-dd84-4c29-a975-d0791c3f2111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c026561030>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global variables for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb49e89-3f99-4fdb-ad90-82383b506124",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc101e60-60d5-4765-b511-a21c6c816637",
   "metadata": {},
   "source": [
    "### CIFAR-10Dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. \n",
    "\n",
    "<img src=\"images/cifar10.png\" width=\"400\" height=\"100\">\n",
    "\n",
    "[CIFAR 10](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e25ea8-b589-45f3-80d8-78477a49d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57edfa7c-ac43-4e7e-adfc-1d9728807a3a",
   "metadata": {},
   "source": [
    "### Twitter Dataset\n",
    "\n",
    "[Source - huggingface.co/datasets - carblacac/twitter-sentiment-analysis](https://huggingface.co/datasets/carblacac/twitter-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ddbad3-7822-4ff9-b6d8-cb2e85214f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target,text</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0,Starting  back at work today   Looks like it...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,Sugar levels dropping... munchies setting in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,@karineb22 yeah!!! have a great summer break!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,hannah montana was very good.  now going to ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              target  text\n",
       "0                                        target,text   NaN\n",
       "1  0,Starting  back at work today   Looks like it...   NaN\n",
       "2  1,Sugar levels dropping... munchies setting in...   NaN\n",
       "3   1,@karineb22 yeah!!! have a great summer break!    NaN\n",
       "4  1,hannah montana was very good.  now going to ...   NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = pd.read_csv(\"data/twitter.csv\", sep=\"\\t\", header=None, names=[\"target\", \"text\"])\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a58143-f218-4674-bca5-3f79d9115e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149986, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc16e8-b519-4e20-8d9d-0d0a81d58474",
   "metadata": {},
   "source": [
    "# EXERCISE 1 - Use CIFAR10 Dataset\n",
    "\n",
    "```classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')```\n",
    "\n",
    "- Build a simple Neural Network without using convolutional layers to predict the image class\n",
    "    - No need to configure the optimization, loss function or predict yet. Only implement the NN architecture as ```class NeuralNetwork(nn.Module)```\n",
    "- Explain your choices for the model architecture e.g., activation layer, input and output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c618e3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43429939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2d42299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Primeira camada 3 canais (RGB) *  32x32 pixels : 3072 → 768 neurónios\n",
    "        self.hidden1 = nn.Linear(3*32*32, 768)\n",
    "        \n",
    "        # Segunda camada oculta: 768 → 384 neurónios\n",
    "        self.hidden2 = nn.Linear(768, 384)\n",
    "        \n",
    "        # Terceira camada oculta: 384 → 192 neurónios\n",
    "        self.hidden3 = nn.Linear(384, 192)\n",
    "        \n",
    "        # Camada de saída: 192 → 10 neurónios (correspondentes às 10 classes do CIFAR-10)\n",
    "        self.out = nn.Linear(192, 10)\n",
    "        \n",
    "        # Dropout com probabilidade de 20% para evitar overfitting\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Achatar a imagem (flatten) para vetor 1D, ada imagem passa a ser um vetor com 3072 números, pronto para entrar numa camada Linear.\n",
    "        x=x.view(-1,32*32*3)\n",
    "        \n",
    "        # Passagem pela primeira camada com ReLU e Dropout\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Segunda camada com ReLU e Dropout\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Terceira camada com ReLU\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        \n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597c514",
   "metadata": {},
   "source": [
    "A rede neural construída é composta por três camadas ocultas e uma camada de saída, desenvolvida para classificar imagens do conjunto de dados CIFAR-10. Como as imagens têm dimensão 32x32 píxeis com 3 canais (RGB), cada imagem é composta por um total de 3072 píxeis. Antes de ser processada pela rede, cada imagem é achatada e  transformando-se num vetor unidimensional com 3072 elementos, o que permite a sua passagem por camadas lineares.\n",
    "\n",
    "A primeira camada oculta da rede transforma este vetor de 3072 valores num vetor de 768 neurónios, ao qual é aplicada a função de ativação ReLU para introduzir não-linearidade. Em seguida, é aplicado um Dropout de 20%, que desativa aleatoriamente uma parte dos neurónios durante o treino, reduzindo o risco de overfitting. Esta combinação (Linear → ReLU → Dropout) repete-se na segunda camada oculta (768 → 384 neurónios) e na terceira camada oculta (384 → 192 neurónios), mantendo a regularização e promovendo uma redução progressiva da dimensionalidade.\n",
    "\n",
    "Por fim, a camada de saída converte os 192 neurónios da última camada oculta num vetor de 10 saídas, correspondentes às 10 classes do CIFAR-10 ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae2fc3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45d8d8-c9bf-49c1-a819-56265ac8842c",
   "metadata": {},
   "source": [
    "# Exercise 2 - Use CIFAR10 Dataset\n",
    "- Set the optimizer, loss function and train your model\n",
    "    - Explain your choices for the optimizer and loss function\n",
    "- Check the performance of your model\n",
    "    - Chose the metric and explain your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42acc51",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar o modelo\n",
    "model = NeuralNetwork()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Definir a função de perda e o otimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1629293e",
   "metadata": {},
   "source": [
    "Nesta secção, é feita a preparação do modelo para o processo de treino.\n",
    "\n",
    "Primeiramente, a classe NeuralNetwork é instanciada, criando-se um objeto chamado model que representa a arquitetura da rede neural definida anteriormente.\n",
    "\n",
    "De seguida, é determinado o dispositivo onde o modelo será treinado. Utiliza-se a função torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), que verifica automaticamente se existe uma placa gráfica (GPU) compatível com CUDA disponível. Se existir, o modelo será treinado na GPU, o que acelera significativamente o processo; caso contrário, o treino decorre no processador (CPU).\n",
    "\n",
    "\n",
    "Depois, define-se a função de perda (loss function), que neste caso é a CrossEntropyLoss. Esta função foi escolhida tendo em conta que temos um problema de classificação multiclasse, como é o caso do CIFAR-10.\n",
    "\n",
    "Por fim, é criado o otimizador, que neste caso é o Adam. É inicializado com os parâmetros do modelo (model.parameters()) e com uma taxa de aprendizagem (learning rate) de 0.001, que controla o quão rapidamente os pesos da rede são ajustados durante o treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0863bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10718047",
   "metadata": {},
   "source": [
    "A função train_one_epoch  recebe como argumentos o modelo, o dataloader (que fornece os dados em lotes), o otimizador, a função de perda e o dispositivo onde os cálculos devem ser realizados (CPU ou GPU).\n",
    "\n",
    "O primeiro passo é colocar o modelo em modo de treino através de model.train(). Este modo ativa componentes como o Dropout, caso existam, garantindo que o comportamento do modelo é o apropriado para a fase de aprendizagem.\n",
    "\n",
    "De seguida, é inicializada uma variável total_loss que irá acumular o valor da perda (erro) ao longo de todos os lotes processados.\n",
    "\n",
    "O ciclo principal da função percorre o dataloader, recebendo os dados (inputs) e os rótulos correspondentes (targets) em cada iteração. \n",
    "\n",
    "As previsões são comparadas com as labels reais através da função de perda (loss_fn), que calcula o erro cometido.\n",
    "\n",
    "Antes de atualizar os pesos do modelo, é necessário limpar os gradientes anteriores com optimizer.zero_grad(). \n",
    "Depois disso, realiza-se a propagação para trás (backward pass), onde os gradientes do erro em relação aos pesos são calculados com loss.backward(). Finalmente, o otimizador atualiza os pesos da rede com optimizer.step().\n",
    "\n",
    "\n",
    "No final  a função calcula a perda média dividindo a perda acumulada pelo número total de lotes, e devolve esse valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1078b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            total_correct += (predictions == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32e005",
   "metadata": {},
   "source": [
    "A função evaluate_model serve para avaliar o desempenho do modelo sobre o conjunto de dados. Esta função recebe como argumentos o modelo a avaliar, o dataloader com os dados a testar, a função de perda utilizada e o dispositivo onde os cálculos devem ser realizados (CPU ou GPU).\n",
    "\n",
    "O  modelo é colocado em modo de avaliação com model.eval(). Esta instrução garante que o modelo se comporta corretamente nesta fase, desativando por exemplo camadas como o Dropout, que só são úteis durante o treino.\n",
    "\n",
    "São depois inicializadas três variáveis: total_loss, para acumular o valor total da perda; total_correct, que conta quantas previsões foram corretas; e total_samples, que regista o número total de amostras avaliadas.\n",
    "\n",
    "O bloco with torch.no_grad() é utilizado para garantir que o PyTorch não calcula nem guarda gradientes durante esta fase, o que melhora o desempenho e reduz o uso de memória, já que não há necessidade de retropropagação nesta etapa.\n",
    "\n",
    "O ciclo for percorre todos os lotes de dados no dataloader. Para cada lote, os dados (inputs) e os rótulos verdadeiros (targets) são enviados para o dispositivo apropriado (GPU ou CPU).\n",
    "\n",
    "\n",
    "As previsões são depois convertidas nas classes previstas pelo modelo, utilizando argmax(dim=1), que seleciona o índice com maior valor de saída (ou seja, a classe mais provável). A função compara estas previsões com os rótulos verdadeiros para contar quantas previsões foram corretas, incrementando total_correct. O número de amostras do lote é igualmente somado ao contador total_samples.\n",
    "\n",
    "Após o ciclo, é calculada a perda média, dividindo o valor total da perda pelo número de lotes (len(dataloader)). A métrica Accuracy  é calculada como a percentagem de previsões corretas em relação ao total de amostras avaliadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "534c1701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10\n",
      "  → Loss Train: 0.8199\n",
      "  → Loss Validation: 1.4114 | Accuracy: 54.53%\n",
      "\n",
      "epoch 2/10\n",
      "  → Loss Train: 0.8033\n",
      "  → Loss Validation: 1.4268 | Accuracy: 55.25%\n",
      "\n",
      "epoch 3/10\n",
      "  → Loss Train: 0.7868\n",
      "  → Loss Validation: 1.4165 | Accuracy: 55.05%\n",
      "\n",
      "epoch 4/10\n",
      "  → Loss Train: 0.7746\n",
      "  → Loss Validation: 1.4473 | Accuracy: 55.40%\n",
      "\n",
      "epoch 5/10\n",
      "  → Loss Train: 0.7564\n",
      "  → Loss Validation: 1.4526 | Accuracy: 55.08%\n",
      "\n",
      "epoch 6/10\n",
      "  → Loss Train: 0.7428\n",
      "  → Loss Validation: 1.4283 | Accuracy: 55.89%\n",
      "\n",
      "epoch 7/10\n",
      "  → Loss Train: 0.7312\n",
      "  → Loss Validation: 1.4531 | Accuracy: 55.67%\n",
      "\n",
      "epoch 8/10\n",
      "  → Loss Train: 0.7177\n",
      "  → Loss Validation: 1.4505 | Accuracy: 55.78%\n",
      "\n",
      "epoch 9/10\n",
      "  → Loss Train: 0.6994\n",
      "  → Loss Validation: 1.5303 | Accuracy: 54.71%\n",
      "\n",
      "epoch 10/10\n",
      "  → Loss Train: 0.6946\n",
      "  → Loss Validation: 1.4731 | Accuracy: 55.75%\n",
      "\n",
      "Treino concluído!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    train_loss = train_model(model, trainloader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate_model(model, testloader, criterion, device)\n",
    "\n",
    "    print(f\"  → Loss Train: {train_loss:.4f}\")\n",
    "    print(f\"  → Loss Validation: {val_loss:.4f} | Accuracy: {val_acc:.2f}%\\n\")\n",
    "\n",
    "print(\"Treino concluído!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33040170",
   "metadata": {},
   "source": [
    "A variável epochs define o número total de iterações a realizar. O ciclo for itera esse número de vezes, controlando a progressão do treino. A cada iteração , imprime-se no ecrã o número da época atual, no formato epoch X/Y, para que o utilizador acompanhe o progresso.\n",
    "\n",
    "Durante cada iteração, são chamadas duas funções principais:\n",
    "\n",
    "   -train_model(...): esta função realiza o treino do modelo com base nos dados de treino (trainloader).\n",
    "\n",
    "   -evaluate_model(...): após o treino, esta função avalia o desempenho do modelo no conjunto de teste (testloader)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d24e55",
   "metadata": {},
   "source": [
    "Ao longo das iterações  observa-se uma redução progressiva da perda de treino, o que indica que o modelo está a conseguir ajustar-se aos dados de treino e a aprender padrões. A perda de treino começa em 0.82 na primeira iteração e desce para 0.69 na última, o que é um comportamento esperado e positivo.\n",
    "\n",
    "No entanto, a perda de validação mantém-se praticamente estável e relativamente alta, a oscilar entre 1.41 e 1.53, sem mostrar sinais claros de melhoria. Isto, aliado a uma Accuracy  também estável, entre 54.5% e 55.9%, sugere que o modelo atingiu um patamar de desempenho limitado com a arquitetura atual e que pode estar a começar a sobreajustar-se (overfitting) aos dados de treino.\n",
    "\n",
    "\n",
    "O modelo está a aprender durante o treino, mas não está a generalizar suficientemente bem para os dados de teste. A arquitetura e os hiperparâmetros permitem um desempenho razoável, com uma accuracy próxima dos 55%, o que está alinhado com redes densas simples (sem camada de convolução). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3e25e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e4040-d39a-44e4-a93d-0d6d680aed54",
   "metadata": {},
   "source": [
    "# Exercise 3 - Use CIFAR10 Dataset\n",
    "- Same as Exercise 1 but now add Convolutional Layers\n",
    "- Explain your choices for the model architecture e.g., activation layer, input and output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f908f6-9c28-4c07-bb2c-c0bd54326f92",
   "metadata": {},
   "source": [
    "# Exercise 4 - Use CIFAR10 Dataset\n",
    "- Same as Exercise 2 but for the CNN arquitecture (model from Exercise 3)\n",
    "\n",
    "- Set the optimizer, loss function and train your model\n",
    "    - Explain your choices for the optimizer and loss function\n",
    "- Check the performance of your model\n",
    "    - Chose the metric and explain your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c8d7a-1808-4715-8fe5-8c1bb5a1e00f",
   "metadata": {},
   "source": [
    "# Exercise 5 - Use Twitter Dataset\n",
    "For the **Text DATA TODO**\n",
    "\n",
    "- Build a Supervised Classification model\n",
    "- Explain your choices for preparing the text for the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
